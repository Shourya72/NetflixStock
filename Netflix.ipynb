{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1L9j7mBKSG1hCrHHmTsOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhyeyvshah/comp560-final-project/blob/main/Netflix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pmdIumBs_McW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # necessary when matplotlib is imported\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plot aesthetics\n",
        "plt.rcParams['figure.dpi'] = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"samithsachidanandan/netflix-stock-price-2002-2025\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "W64XQNnHBCwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Netflix Inc. (NFLX) Stock Price 2002-2025.csv', encoding='utf-8-sig')\n",
        "\n",
        "# Clean column names by stripping any extra whitespace\n",
        "df.columns = [col.strip() for col in df.columns]\n",
        "\n",
        "# Convert the Date column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "\n",
        "# Convert numeric columns from string to float (this will handle commas if present)\n",
        "numeric_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "for col in numeric_columns:\n",
        "    # Remove any commas and extra spaces, then convert to numeric\n",
        "    df[col] = pd.to_numeric(df[col].str.replace(',', '').str.strip(), errors='coerce')\n",
        "\n",
        "# Quick check of the DataFrame structure\n",
        "print('DataFrame loaded with shape:', df.shape)\n",
        "print('Columns:', df.columns.tolist())"
      ],
      "metadata": {
        "id": "NNWJHsivBGHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Missing values per column:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing Date or Close values (as these are critical)\n",
        "df = df.dropna(subset=['Date', 'Close']).reset_index(drop=True)\n",
        "\n",
        "# Sort data by Date\n",
        "df = df.sort_values('Date')\n",
        "\n",
        "# Create a new feature: number of days since the first observation\n",
        "df['Days'] = (df['Date'] - df['Date'].min()).dt.days\n",
        "\n",
        "print('\\nDataFrame shape after cleaning:', df.shape)"
      ],
      "metadata": {
        "id": "IDvVuIr-BIvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df['Close'], kde=True, color='blue')\n",
        "plt.title('Distribution of Close Prices')\n",
        "plt.xlabel('Close Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.savefig('hist_close.png')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df['Volume'], kde=True, color='orange')\n",
        "plt.title('Distribution of Volume')\n",
        "plt.xlabel('Volume')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.savefig('hist_volume.png')\n",
        "plt.show()\n",
        "\n",
        "# Box Plot to examine outliers in 'Close' prices\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=df['Close'], color='green')\n",
        "plt.title('Box Plot of Close Prices')\n",
        "plt.tight_layout()\n",
        "plt.savefig('boxplot_close.png')\n",
        "plt.show()\n",
        "\n",
        "# Create a correlation heatmap for numeric columns if there are four or more\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "if numeric_df.shape[1] >= 4:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "    plt.title('Correlation Heatmap for Numeric Features')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('correlation_heatmap.png')\n",
        "    plt.show()\n",
        "\n",
        "# Pair Plot for key features\n",
        "sns.pairplot(df[['Days', 'Open', 'Close', 'Adj Close']])\n",
        "plt.savefig('pairplot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ydJK5LULBZFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Daily_Return'] = (df['Close'] - df['Open']) / df['Open']\n",
        "df['5_MA'] = df['Close'].rolling(window=5).mean()\n",
        "df['10_MA'] = df['Close'].rolling(window=10).mean()\n",
        "df['Volatility'] = df['Close'].rolling(window=5).std()\n",
        "\n",
        "# Drop NaN values caused by rolling window calculations\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Create Target Variable (1 for Up, 0 for Down)\n",
        "df['Price_Movement'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
        "\n",
        "# Select Features and Target\n",
        "features = ['Open','Close', 'Daily_Return', '5_MA', '10_MA', 'Volatility']\n",
        "X = df[features]\n",
        "y = df['Price_Movement']\n",
        "\n",
        "# Split into Train and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10, shuffle=True)\n",
        "\n",
        "# Train Na√Øve Bayes Model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "q6xlLsM9Bfdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Ww_F3Nm5Bs6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Daily_Return', '5_MA', '10_MA']\n",
        "X = df[features].values\n",
        "y = df['Price_Movement'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
        "\n",
        "# Define the Gaussian Naive Bayes Classifier with Mini-Batch Gradient Descent\n",
        "class MiniBatchGaussianNB:\n",
        "    def __init__(self, batch_size=32, learning_rate=0.01, epochs=100):\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.classes = np.unique(y)\n",
        "        self.means = {c: np.zeros(n_features) for c in self.classes}\n",
        "        self.variances = {c: np.ones(n_features) for c in self.classes}\n",
        "        self.priors = {c: np.sum(y == c) / n_samples for c in self.classes}\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            indices = np.random.permutation(n_samples)\n",
        "            X_shuffled, y_shuffled = X[indices], y[indices]\n",
        "\n",
        "            for i in range(0, n_samples, self.batch_size):\n",
        "                X_batch = X_shuffled[i:i+self.batch_size]\n",
        "                y_batch = y_shuffled[i:i+self.batch_size]\n",
        "\n",
        "                for c in self.classes:\n",
        "                    X_c = X_batch[y_batch == c]\n",
        "                    if len(X_c) == 0:\n",
        "                        continue\n",
        "\n",
        "                    # Compute gradients for mean and variance\n",
        "                    grad_mean = np.mean(X_c, axis=0) - self.means[c]\n",
        "                    grad_var = np.var(X_c, axis=0) - self.variances[c]\n",
        "\n",
        "                    # Gradient descent updates\n",
        "                    self.means[c] += self.learning_rate * grad_mean\n",
        "                    self.variances[c] += self.learning_rate * grad_var\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch}: Mean update {self.means}, Variance update {self.variances}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs = np.zeros((X.shape[0], len(self.classes)))\n",
        "\n",
        "        for i, c in enumerate(self.classes):\n",
        "            mean, var = self.means[c], self.variances[c]\n",
        "            likelihood = (1 / np.sqrt(2 * np.pi * var)) * np.exp(-((X - mean) ** 2) / (2 * var))\n",
        "            probs[:, i] = np.prod(likelihood, axis=1) * self.priors[c]\n",
        "\n",
        "        return np.argmax(probs, axis=1)\n",
        "\n",
        "# Train the Model\n",
        "model = MiniBatchGaussianNB(batch_size=32, learning_rate=0.0001, epochs=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "yMEAUj6fBlkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Uju8_us_Bq0N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}